{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f6b65c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gensim\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "from scipy import spatial\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c608c99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utils\n",
    "def readjson(filename): #Reads JSON data\n",
    "    reader = open(filename)\n",
    "    data = json.load(reader)\n",
    "    reader.close()\n",
    "\n",
    "    return data\n",
    "\n",
    "def writejson(data,filename):\n",
    "    writer = open(filename,'w')\n",
    "    json.dump(data,writer)\n",
    "    writer.close()\n",
    "\n",
    "def textclean(text): #Cleans text\n",
    "    #Converts to lowercase, removes punctuation, unicode and newlines\n",
    "    #text = text.lower()\n",
    "    #text = text.encode('ascii', 'ignore').decode()\n",
    "    text = re.sub(r'https*\\S+', ' ', text)\n",
    "    text = re.sub(r'@\\S+', ' ', text)\n",
    "    text = re.sub(r'#\\S+', ' ', text)\n",
    "    text = re.sub(r'\\'\\w+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text)\n",
    "    text = re.sub(r'\\w*\\d+\\w*', '', text)\n",
    "    text = re.sub(r'\\s{2,}', ' ', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def corpusort(text): #Sorts input into documents and titles\n",
    "    doc = []\n",
    "    title = []\n",
    "    for i in tqdm(range(len(text))):\n",
    "        header = text[i][0]\n",
    "        \n",
    "        if header[0:3] == 'doc':\n",
    "            doc.append(text[i])\n",
    "        else:\n",
    "            title.append(text[i])\n",
    "    return doc,title\n",
    "\n",
    "def cleandocs(docs): #Tokenises and preps the document data\n",
    "    clean_docs = []\n",
    "    for i in tqdm(range(len(docs))):\n",
    "        tokens = gensim.utils.simple_preprocess(textclean(docs[i][1]))\n",
    "        clean_docs.append(gensim.models.doc2vec.TaggedDocument(tokens,[docs[i][0]]))\n",
    "\n",
    "    return clean_docs\n",
    "\n",
    "def cleantitles(titles): #Tokenises and preps the title data\n",
    "    clean_titles = []\n",
    "    for i in tqdm(range(len(titles))):\n",
    "        clean_titles.append([gensim.utils.simple_preprocess(textclean(titles[i][1])),titles[i][0]])\n",
    "    \n",
    "    return clean_titles\n",
    "\n",
    "def cosinerank(primary,array):\n",
    "    dist = []\n",
    "    vector1 = model.infer_vector(primary)\n",
    "    for i in range(len(array)):\n",
    "        vector2 = model.infer_vector(array[i][0])\n",
    "        dist.append([spatial.distance.cosine(vector1,vector2),array[i][1]])\n",
    "    \n",
    "    return (sorted(dist, key = lambda tup: tup[0]))\n",
    "\n",
    "def docsearch(query):\n",
    "    for text,tag in docs:\n",
    "        if query == tag:\n",
    "            return [text,tag]\n",
    "        else:\n",
    "            continue\n",
    "    return \"oof\"\n",
    "\n",
    "def titlesearch(query):\n",
    "    for text,tag in titles:\n",
    "        if query == tag:\n",
    "            return [text,tag]\n",
    "        else:\n",
    "            continue\n",
    "    return \"oof\"\n",
    "\n",
    "def docmatch(ranks, recdocs):\n",
    "    res = []\n",
    "    count = 0\n",
    "    \n",
    "    for i in range(len(ranks)):\n",
    "        if ranks[i][0] in recdocs:\n",
    "            res.append(ranks[i][0])\n",
    "        if count==len(recdocs):\n",
    "            return res\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "13fdff49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 35080/35080 [00:00<00:00, 1349526.58it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 17540/17540 [00:27<00:00, 635.76it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 17540/17540 [00:00<00:00, 41954.45it/s]\n",
      "2021-08-28 05:05:44,685 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec(dm/m,d50,n5,w5,s0.001,t3)', 'datetime': '2021-08-28T05:05:44.685206', 'gensim': '4.0.1', 'python': '3.8.9 (tags/v3.8.9:a743f81, Apr  2 2021, 11:10:41) [MSC v.1928 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n",
      "2021-08-28 05:05:44,735 : INFO : collecting all words and their counts\n",
      "2021-08-28 05:05:44,736 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2021-08-28 05:05:46,759 : INFO : PROGRESS: at example #10000, processed 6130913 words (3030552/s), 167489 word types, 10000 tags\n",
      "2021-08-28 05:05:47,991 : INFO : collected 234838 word types and 17540 unique tags from a corpus of 17540 examples and 10765634 words\n",
      "2021-08-28 05:05:47,992 : INFO : Creating a fresh vocabulary\n",
      "2021-08-28 05:05:48,838 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 234838 unique words (100.0%% of original 234838, drops 0)', 'datetime': '2021-08-28T05:05:48.838430', 'gensim': '4.0.1', 'python': '3.8.9 (tags/v3.8.9:a743f81, Apr  2 2021, 11:10:41) [MSC v.1928 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-08-28 05:05:48,839 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 10765634 word corpus (100.0%% of original 10765634, drops 0)', 'datetime': '2021-08-28T05:05:48.839429', 'gensim': '4.0.1', 'python': '3.8.9 (tags/v3.8.9:a743f81, Apr  2 2021, 11:10:41) [MSC v.1928 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-08-28 05:05:50,067 : INFO : deleting the raw counts dictionary of 234838 items\n",
      "2021-08-28 05:05:50,075 : INFO : sample=0.001 downsamples 29 most-common words\n",
      "2021-08-28 05:05:50,076 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 8370622.705747915 word corpus (77.8%% of prior 10765634)', 'datetime': '2021-08-28T05:05:50.075645', 'gensim': '4.0.1', 'python': '3.8.9 (tags/v3.8.9:a743f81, Apr  2 2021, 11:10:41) [MSC v.1928 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-08-28 05:05:52,177 : INFO : estimated required memory for 234838 words and 50 dimensions: 218370200 bytes\n",
      "2021-08-28 05:05:52,178 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "#Main\n",
    "corpus = readjson('data/corpus.json')\n",
    "docs, titles = corpusort(corpus)\n",
    "\n",
    "docs = cleandocs(docs)\n",
    "titles = cleantitles(titles)\n",
    "\n",
    "model = gensim.models.doc2vec.Doc2Vec(vector_size = 50, min_count = 1, epochs = 10)\n",
    "model.build_vocab(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c31e41d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-28 05:05:52,263 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 234838 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5', 'datetime': '2021-08-28T05:05:52.263025', 'gensim': '4.0.1', 'python': '3.8.9 (tags/v3.8.9:a743f81, Apr  2 2021, 11:10:41) [MSC v.1928 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2021-08-28 05:05:53,270 : INFO : EPOCH 1 - PROGRESS: at 13.31% examples, 1112326 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:05:54,271 : INFO : EPOCH 1 - PROGRESS: at 27.57% examples, 1141457 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:05:55,283 : INFO : EPOCH 1 - PROGRESS: at 41.37% examples, 1141741 words/s, in_qsize 6, out_qsize 0\n",
      "2021-08-28 05:05:56,293 : INFO : EPOCH 1 - PROGRESS: at 55.52% examples, 1155217 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:05:57,305 : INFO : EPOCH 1 - PROGRESS: at 69.53% examples, 1158526 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:05:58,320 : INFO : EPOCH 1 - PROGRESS: at 83.63% examples, 1157580 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:05:59,326 : INFO : EPOCH 1 - PROGRESS: at 96.31% examples, 1145360 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:05:59,606 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-08-28 05:05:59,610 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-08-28 05:05:59,617 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-08-28 05:05:59,618 : INFO : EPOCH - 1 : training on 10765634 raw words (8388298 effective words) took 7.4s, 1141021 effective words/s\n",
      "2021-08-28 05:06:00,625 : INFO : EPOCH 2 - PROGRESS: at 12.07% examples, 1006900 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:01,633 : INFO : EPOCH 2 - PROGRESS: at 25.95% examples, 1069882 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:02,635 : INFO : EPOCH 2 - PROGRESS: at 39.24% examples, 1083972 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:03,638 : INFO : EPOCH 2 - PROGRESS: at 51.84% examples, 1079133 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:04,646 : INFO : EPOCH 2 - PROGRESS: at 64.66% examples, 1079361 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:05,652 : INFO : EPOCH 2 - PROGRESS: at 78.34% examples, 1090748 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:06,658 : INFO : EPOCH 2 - PROGRESS: at 92.29% examples, 1097607 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:07,229 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-08-28 05:06:07,232 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-08-28 05:06:07,236 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-08-28 05:06:07,236 : INFO : EPOCH - 2 : training on 10765634 raw words (8388416 effective words) took 7.6s, 1101509 effective words/s\n",
      "2021-08-28 05:06:08,239 : INFO : EPOCH 3 - PROGRESS: at 13.40% examples, 1122455 words/s, in_qsize 4, out_qsize 1\n",
      "2021-08-28 05:06:09,239 : INFO : EPOCH 3 - PROGRESS: at 27.50% examples, 1139162 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:10,239 : INFO : EPOCH 3 - PROGRESS: at 41.28% examples, 1144344 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:11,249 : INFO : EPOCH 3 - PROGRESS: at 54.84% examples, 1144783 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:12,253 : INFO : EPOCH 3 - PROGRESS: at 69.06% examples, 1156297 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:13,265 : INFO : EPOCH 3 - PROGRESS: at 82.91% examples, 1152417 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:14,268 : INFO : EPOCH 3 - PROGRESS: at 96.68% examples, 1154215 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:14,507 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-08-28 05:06:14,510 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-08-28 05:06:14,515 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-08-28 05:06:14,516 : INFO : EPOCH - 3 : training on 10765634 raw words (8387232 effective words) took 7.3s, 1152498 effective words/s\n",
      "2021-08-28 05:06:15,518 : INFO : EPOCH 4 - PROGRESS: at 14.14% examples, 1183149 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:16,522 : INFO : EPOCH 4 - PROGRESS: at 28.70% examples, 1187064 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:17,522 : INFO : EPOCH 4 - PROGRESS: at 43.15% examples, 1194199 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:18,534 : INFO : EPOCH 4 - PROGRESS: at 57.09% examples, 1192006 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:19,538 : INFO : EPOCH 4 - PROGRESS: at 71.77% examples, 1200031 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:20,549 : INFO : EPOCH 4 - PROGRESS: at 86.31% examples, 1199363 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:21,556 : INFO : EPOCH 4 - PROGRESS: at 99.81% examples, 1189676 words/s, in_qsize 2, out_qsize 1\n",
      "2021-08-28 05:06:21,557 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-08-28 05:06:21,558 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-08-28 05:06:21,559 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-08-28 05:06:21,559 : INFO : EPOCH - 4 : training on 10765634 raw words (8388811 effective words) took 7.0s, 1191346 effective words/s\n",
      "2021-08-28 05:06:22,561 : INFO : EPOCH 5 - PROGRESS: at 14.26% examples, 1191568 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:23,562 : INFO : EPOCH 5 - PROGRESS: at 27.77% examples, 1150759 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:24,564 : INFO : EPOCH 5 - PROGRESS: at 42.08% examples, 1166331 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:25,582 : INFO : EPOCH 5 - PROGRESS: at 56.30% examples, 1173550 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:26,588 : INFO : EPOCH 5 - PROGRESS: at 70.46% examples, 1176026 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:27,588 : INFO : EPOCH 5 - PROGRESS: at 84.26% examples, 1170939 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:28,595 : INFO : EPOCH 5 - PROGRESS: at 98.71% examples, 1176945 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:28,676 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-08-28 05:06:28,678 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-08-28 05:06:28,678 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-08-28 05:06:28,679 : INFO : EPOCH - 5 : training on 10765634 raw words (8387100 effective words) took 7.1s, 1178364 effective words/s\n",
      "2021-08-28 05:06:29,693 : INFO : EPOCH 6 - PROGRESS: at 14.26% examples, 1177446 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:30,696 : INFO : EPOCH 6 - PROGRESS: at 28.70% examples, 1180675 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:31,709 : INFO : EPOCH 6 - PROGRESS: at 42.30% examples, 1162008 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:32,710 : INFO : EPOCH 6 - PROGRESS: at 56.13% examples, 1167693 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:33,713 : INFO : EPOCH 6 - PROGRESS: at 69.70% examples, 1163018 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:34,717 : INFO : EPOCH 6 - PROGRESS: at 84.26% examples, 1169442 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:35,723 : INFO : EPOCH 6 - PROGRESS: at 98.71% examples, 1175720 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:35,806 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-08-28 05:06:35,810 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-08-28 05:06:35,811 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-08-28 05:06:35,812 : INFO : EPOCH - 6 : training on 10765634 raw words (8387885 effective words) took 7.1s, 1176331 effective words/s\n",
      "2021-08-28 05:06:36,815 : INFO : EPOCH 7 - PROGRESS: at 14.62% examples, 1218738 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:37,816 : INFO : EPOCH 7 - PROGRESS: at 29.37% examples, 1217453 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:38,828 : INFO : EPOCH 7 - PROGRESS: at 43.68% examples, 1204430 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:39,830 : INFO : EPOCH 7 - PROGRESS: at 57.02% examples, 1189950 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:40,831 : INFO : EPOCH 7 - PROGRESS: at 71.60% examples, 1197595 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-28 05:06:41,839 : INFO : EPOCH 7 - PROGRESS: at 85.75% examples, 1192938 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:42,837 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-08-28 05:06:42,841 : INFO : EPOCH 7 - PROGRESS: at 99.97% examples, 1193234 words/s, in_qsize 1, out_qsize 1\n",
      "2021-08-28 05:06:42,842 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-08-28 05:06:42,848 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-08-28 05:06:42,849 : INFO : EPOCH - 7 : training on 10765634 raw words (8389144 effective words) took 7.0s, 1192377 effective words/s\n",
      "2021-08-28 05:06:43,853 : INFO : EPOCH 8 - PROGRESS: at 13.59% examples, 1136358 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:44,857 : INFO : EPOCH 8 - PROGRESS: at 28.40% examples, 1174634 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:45,863 : INFO : EPOCH 8 - PROGRESS: at 43.06% examples, 1188467 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:46,865 : INFO : EPOCH 8 - PROGRESS: at 56.73% examples, 1185378 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:47,866 : INFO : EPOCH 8 - PROGRESS: at 71.17% examples, 1191205 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:48,871 : INFO : EPOCH 8 - PROGRESS: at 85.19% examples, 1186335 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:49,875 : INFO : EPOCH 8 - PROGRESS: at 99.78% examples, 1191659 words/s, in_qsize 3, out_qsize 0\n",
      "2021-08-28 05:06:49,884 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-08-28 05:06:49,886 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-08-28 05:06:49,890 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-08-28 05:06:49,891 : INFO : EPOCH - 8 : training on 10765634 raw words (8387489 effective words) took 7.0s, 1191579 effective words/s\n",
      "2021-08-28 05:06:50,896 : INFO : EPOCH 9 - PROGRESS: at 14.52% examples, 1210771 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:51,904 : INFO : EPOCH 9 - PROGRESS: at 28.40% examples, 1171737 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:52,914 : INFO : EPOCH 9 - PROGRESS: at 42.88% examples, 1179902 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:53,915 : INFO : EPOCH 9 - PROGRESS: at 56.30% examples, 1173596 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:54,921 : INFO : EPOCH 9 - PROGRESS: at 70.63% examples, 1179020 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:55,924 : INFO : EPOCH 9 - PROGRESS: at 84.77% examples, 1178084 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:56,925 : INFO : EPOCH 9 - PROGRESS: at 98.27% examples, 1172234 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:06:57,053 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-08-28 05:06:57,055 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-08-28 05:06:57,063 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-08-28 05:06:57,064 : INFO : EPOCH - 9 : training on 10765634 raw words (8388049 effective words) took 7.2s, 1169833 effective words/s\n",
      "2021-08-28 05:06:58,080 : INFO : EPOCH 10 - PROGRESS: at 11.48% examples, 952621 words/s, in_qsize 6, out_qsize 0\n",
      "2021-08-28 05:06:59,083 : INFO : EPOCH 10 - PROGRESS: at 23.39% examples, 959344 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:07:00,089 : INFO : EPOCH 10 - PROGRESS: at 36.37% examples, 1000618 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:07:01,102 : INFO : EPOCH 10 - PROGRESS: at 49.98% examples, 1035244 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:07:02,107 : INFO : EPOCH 10 - PROGRESS: at 63.59% examples, 1058376 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:07:03,115 : INFO : EPOCH 10 - PROGRESS: at 77.67% examples, 1078849 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:07:04,117 : INFO : EPOCH 10 - PROGRESS: at 91.13% examples, 1082692 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:07:04,798 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-08-28 05:07:04,805 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-08-28 05:07:04,813 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-08-28 05:07:04,814 : INFO : EPOCH - 10 : training on 10765634 raw words (8388804 effective words) took 7.7s, 1082833 effective words/s\n",
      "2021-08-28 05:07:04,815 : INFO : Doc2Vec lifecycle event {'msg': 'training on 107656340 raw words (83881228 effective words) took 72.5s, 1156191 effective words/s', 'datetime': '2021-08-28T05:07:04.815153', 'gensim': '4.0.1', 'python': '3.8.9 (tags/v3.8.9:a743f81, Apr  2 2021, 11:10:41) [MSC v.1928 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n"
     ]
    }
   ],
   "source": [
    "#Model Training\n",
    "model.train(docs, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fe157a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-90-777e82f68245>:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  docs = np.array(docs)\n",
      "<ipython-input-90-777e82f68245>:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  titles = np.array(titles)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3508/3508 [02:53<00:00, 20.25it/s]\n"
     ]
    }
   ],
   "source": [
    "#Read the test JSON and rank stuff\n",
    "to_tag = readjson('data/test_q.json')\n",
    "docs = np.array(docs)\n",
    "titles = np.array(titles)\n",
    "results = to_tag\n",
    "\n",
    "for i in tqdm(range(len(to_tag))):\n",
    "    to_check = to_tag[i]['title_id']\n",
    "    to_check = titlesearch(to_check)\n",
    "    \n",
    "    title_vector = model.infer_vector(to_check[0])\n",
    "    ranking = model.dv.most_similar([title_vector],topn=len(model.dv))\n",
    "    results[i]['candidates'] = docmatch(ranking,to_tag[i]['candidates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8eadc6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#Read the test JSON and rank stuff\\nto_tag = readjson('data/test_q.json')\\ndocs = np.array(docs)\\ntitles = np.array(titles)\\nresults = to_tag\\n\\nfor i in tqdm(range(len(to_tag))):\\n    taglist = to_tag[i]['candidates']\\n    \\n    doc_tokens = []\\n    for key in taglist:\\n        val = np.where(docs==key)\\n        doc_tokens.append(docs[(val[0][0])])\\n        \\n    val = np.where(titles==to_tag[i]['title_id'])\\n    title_token = titles[(val[0][0])][0]\\n    \\n    sorted_docs = cosinerank(title_token,doc_tokens)\\n    \\n    sorted_docs_column = []\\n    for j in range(len(sorted_docs)):\\n        sorted_docs_column.append(sorted_docs[j][1])\\n    results[i]['candidates'] = sorted_docs_column\\n\""
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Read the test JSON and rank stuff\n",
    "to_tag = readjson('data/test_q.json')\n",
    "docs = np.array(docs)\n",
    "titles = np.array(titles)\n",
    "results = to_tag\n",
    "\n",
    "for i in tqdm(range(len(to_tag))):\n",
    "    taglist = to_tag[i]['candidates']\n",
    "    \n",
    "    doc_tokens = []\n",
    "    for key in taglist:\n",
    "        val = np.where(docs==key)\n",
    "        doc_tokens.append(docs[(val[0][0])])\n",
    "        \n",
    "    val = np.where(titles==to_tag[i]['title_id'])\n",
    "    title_token = titles[(val[0][0])][0]\n",
    "    \n",
    "    sorted_docs = cosinerank(title_token,doc_tokens)\n",
    "    \n",
    "    sorted_docs_column = []\n",
    "    for j in range(len(sorted_docs)):\n",
    "        sorted_docs_column.append(sorted_docs[j][1])\n",
    "    results[i]['candidates'] = sorted_docs_column\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d98732a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "writejson(results,'data/suggestion.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ef6fb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
