{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6b65c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\quagzlor\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import gensim\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "from scipy import spatial\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c608c99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utils\n",
    "def readjson(filename): #Reads JSON data\n",
    "    reader = open(filename)\n",
    "    data = json.load(reader)\n",
    "    reader.close()\n",
    "\n",
    "    return data\n",
    "\n",
    "def writejson(data,filename):\n",
    "    writer = open(filename,'w')\n",
    "    json.dump(data,writer)\n",
    "    writer.close()\n",
    "\n",
    "def textclean(text): #Cleans text\n",
    "    #Converts to lowercase, removes punctuation, unicode and newlines\n",
    "    #text = text.lower()\n",
    "    #text = text.encode('ascii', 'ignore').decode()\n",
    "    text = re.sub(r'https*\\S+', ' ', text)\n",
    "    text = re.sub(r'@\\S+', ' ', text)\n",
    "    text = re.sub(r'#\\S+', ' ', text)\n",
    "    text = re.sub(r'\\'\\w+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text)\n",
    "    text = re.sub(r'\\w*\\d+\\w*', '', text)\n",
    "    text = re.sub(r'\\s{2,}', ' ', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def corpusort(text): #Sorts input into documents and titles\n",
    "    doc = []\n",
    "    title = []\n",
    "    for i in tqdm(range(len(text))):\n",
    "        header = text[i][0]\n",
    "        \n",
    "        if header[0:3] == 'doc':\n",
    "            doc.append(text[i])\n",
    "        else:\n",
    "            title.append(text[i])\n",
    "    return doc,title\n",
    "\n",
    "def cleandocs(docs): #Tokenises and preps the document data\n",
    "    clean_docs = []\n",
    "    for i in tqdm(range(len(docs))):\n",
    "        tokens = gensim.utils.simple_preprocess(textclean(docs[i][1]))\n",
    "        clean_docs.append(gensim.models.doc2vec.TaggedDocument(tokens,[docs[i][0]]))\n",
    "\n",
    "    return clean_docs\n",
    "\n",
    "def cleantitles(titles): #Tokenises and preps the title data\n",
    "    clean_titles = []\n",
    "    for i in tqdm(range(len(titles))):\n",
    "        clean_titles.append([gensim.utils.simple_preprocess(textclean(titles[i][1])),titles[i][0]])\n",
    "    \n",
    "    return clean_titles\n",
    "\n",
    "def cosinerank(primary,array):\n",
    "    dist = []\n",
    "    #vector1 = model.infer_vector(primary)\n",
    "    vector1 = primary\n",
    "    for i in range(len(array)):\n",
    "        vector2 = model.dv[array[i]]\n",
    "        dist.append([spatial.distance.cosine(vector1,vector2),array[i]])\n",
    "    \n",
    "    return (sorted(dist, key = lambda tup: tup[0]))\n",
    "\n",
    "def docsearch(query):\n",
    "    for text,tag in docs:\n",
    "        if query == tag:\n",
    "            return [text,tag]\n",
    "        else:\n",
    "            continue\n",
    "    return \"oof\"\n",
    "\n",
    "def titlesearch(query):\n",
    "    for text,tag in titles:\n",
    "        if query == tag:\n",
    "            return [text,tag]\n",
    "        else:\n",
    "            continue\n",
    "    return \"oof\"\n",
    "\n",
    "def docmatch(ranks, recdocs):\n",
    "    res = []\n",
    "    count = 0\n",
    "    \n",
    "    for i in range(len(ranks)):\n",
    "        if ranks[i][0] in recdocs:\n",
    "            res.append(ranks[i][0])\n",
    "        if count==len(recdocs):\n",
    "            return res\n",
    "    return res\n",
    "\n",
    "def scramble(res):\n",
    "    size = len(res)\n",
    "    new_res = res[((size/4)*3):] + res[(size/4):((size/4)*3)] + res[:(size/4)]\n",
    "    return new_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13fdff49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 35080/35080 [00:00<00:00, 3045604.20it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 17540/17540 [00:24<00:00, 706.74it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 17540/17540 [00:00<00:00, 37208.28it/s]\n",
      "2021-08-28 05:55:30,804 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec(dm/m,d150,n5,w5,s0.001,t3)', 'datetime': '2021-08-28T05:55:30.803429', 'gensim': '4.0.1', 'python': '3.8.9 (tags/v3.8.9:a743f81, Apr  2 2021, 11:10:41) [MSC v.1928 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n",
      "2021-08-28 05:55:30,805 : INFO : collecting all words and their counts\n",
      "2021-08-28 05:55:30,805 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2021-08-28 05:55:31,778 : INFO : PROGRESS: at example #10000, processed 6130913 words (6307286/s), 167489 word types, 10000 tags\n",
      "2021-08-28 05:55:32,599 : INFO : collected 234838 word types and 17540 unique tags from a corpus of 17540 examples and 10765634 words\n",
      "2021-08-28 05:55:32,600 : INFO : Creating a fresh vocabulary\n",
      "2021-08-28 05:55:33,274 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 234838 unique words (100.0%% of original 234838, drops 0)', 'datetime': '2021-08-28T05:55:33.274727', 'gensim': '4.0.1', 'python': '3.8.9 (tags/v3.8.9:a743f81, Apr  2 2021, 11:10:41) [MSC v.1928 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-08-28 05:55:33,275 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 10765634 word corpus (100.0%% of original 10765634, drops 0)', 'datetime': '2021-08-28T05:55:33.275613', 'gensim': '4.0.1', 'python': '3.8.9 (tags/v3.8.9:a743f81, Apr  2 2021, 11:10:41) [MSC v.1928 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-08-28 05:55:34,353 : INFO : deleting the raw counts dictionary of 234838 items\n",
      "2021-08-28 05:55:34,358 : INFO : sample=0.001 downsamples 29 most-common words\n",
      "2021-08-28 05:55:34,359 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 8370622.705747915 word corpus (77.8%% of prior 10765634)', 'datetime': '2021-08-28T05:55:34.359301', 'gensim': '4.0.1', 'python': '3.8.9 (tags/v3.8.9:a743f81, Apr  2 2021, 11:10:41) [MSC v.1928 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-08-28 05:55:36,182 : INFO : estimated required memory for 234838 words and 150 dimensions: 413256600 bytes\n",
      "2021-08-28 05:55:36,183 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "#Main\n",
    "corpus = readjson('data/corpus.json')\n",
    "docs, titles = corpusort(corpus)\n",
    "\n",
    "docs = cleandocs(docs)\n",
    "titles = cleantitles(titles)\n",
    "\n",
    "model = gensim.models.doc2vec.Doc2Vec(vector_size = 150, min_count = 1, epochs = 10)\n",
    "model.build_vocab(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c31e41d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-28 05:55:36,350 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 234838 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=5', 'datetime': '2021-08-28T05:55:36.350376', 'gensim': '4.0.1', 'python': '3.8.9 (tags/v3.8.9:a743f81, Apr  2 2021, 11:10:41) [MSC v.1928 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2021-08-28 05:55:37,367 : INFO : EPOCH 1 - PROGRESS: at 11.98% examples, 989477 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:55:38,375 : INFO : EPOCH 1 - PROGRESS: at 23.73% examples, 971054 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:55:39,381 : INFO : EPOCH 1 - PROGRESS: at 36.10% examples, 991380 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:55:40,386 : INFO : EPOCH 1 - PROGRESS: at 48.10% examples, 994942 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:55:41,391 : INFO : EPOCH 1 - PROGRESS: at 59.98% examples, 997913 words/s, in_qsize 6, out_qsize 0\n",
      "2021-08-28 05:55:42,391 : INFO : EPOCH 1 - PROGRESS: at 71.85% examples, 998746 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:55:43,412 : INFO : EPOCH 1 - PROGRESS: at 84.00% examples, 996835 words/s, in_qsize 6, out_qsize 0\n",
      "2021-08-28 05:55:44,414 : INFO : EPOCH 1 - PROGRESS: at 95.79% examples, 997611 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:55:44,746 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-08-28 05:55:44,760 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-08-28 05:55:44,766 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-08-28 05:55:44,766 : INFO : EPOCH - 1 : training on 10765634 raw words (8388709 effective words) took 8.4s, 996971 effective words/s\n",
      "2021-08-28 05:55:45,773 : INFO : EPOCH 2 - PROGRESS: at 12.16% examples, 1014066 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:55:46,773 : INFO : EPOCH 2 - PROGRESS: at 24.52% examples, 1013239 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:55:47,782 : INFO : EPOCH 2 - PROGRESS: at 36.80% examples, 1016120 words/s, in_qsize 6, out_qsize 0\n",
      "2021-08-28 05:55:48,790 : INFO : EPOCH 2 - PROGRESS: at 49.01% examples, 1018166 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:55:49,796 : INFO : EPOCH 2 - PROGRESS: at 61.21% examples, 1020748 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:55:50,800 : INFO : EPOCH 2 - PROGRESS: at 73.51% examples, 1023391 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:55:51,806 : INFO : EPOCH 2 - PROGRESS: at 85.93% examples, 1023370 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:55:52,823 : INFO : EPOCH 2 - PROGRESS: at 98.35% examples, 1024322 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:55:52,940 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-08-28 05:55:52,940 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-08-28 05:55:52,949 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-08-28 05:55:52,950 : INFO : EPOCH - 2 : training on 10765634 raw words (8387872 effective words) took 8.2s, 1025206 effective words/s\n",
      "2021-08-28 05:55:53,959 : INFO : EPOCH 3 - PROGRESS: at 12.08% examples, 1004176 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:55:54,959 : INFO : EPOCH 3 - PROGRESS: at 24.25% examples, 1000705 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:55:55,961 : INFO : EPOCH 3 - PROGRESS: at 35.92% examples, 992690 words/s, in_qsize 6, out_qsize 0\n",
      "2021-08-28 05:55:56,962 : INFO : EPOCH 3 - PROGRESS: at 48.02% examples, 999074 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:55:57,972 : INFO : EPOCH 3 - PROGRESS: at 60.23% examples, 1005926 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:55:58,972 : INFO : EPOCH 3 - PROGRESS: at 72.29% examples, 1007926 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:55:59,974 : INFO : EPOCH 3 - PROGRESS: at 84.58% examples, 1009500 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:00,976 : INFO : EPOCH 3 - PROGRESS: at 96.49% examples, 1009489 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:01,241 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-08-28 05:56:01,249 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-08-28 05:56:01,255 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-08-28 05:56:01,256 : INFO : EPOCH - 3 : training on 10765634 raw words (8388260 effective words) took 8.3s, 1010159 effective words/s\n",
      "2021-08-28 05:56:02,263 : INFO : EPOCH 4 - PROGRESS: at 11.96% examples, 997956 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:03,266 : INFO : EPOCH 4 - PROGRESS: at 24.69% examples, 1018948 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:04,270 : INFO : EPOCH 4 - PROGRESS: at 36.80% examples, 1016810 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:05,277 : INFO : EPOCH 4 - PROGRESS: at 48.95% examples, 1016784 words/s, in_qsize 4, out_qsize 1\n",
      "2021-08-28 05:56:06,278 : INFO : EPOCH 4 - PROGRESS: at 60.87% examples, 1016431 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:07,285 : INFO : EPOCH 4 - PROGRESS: at 72.91% examples, 1015425 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:08,291 : INFO : EPOCH 4 - PROGRESS: at 85.47% examples, 1018483 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:09,302 : INFO : EPOCH 4 - PROGRESS: at 97.72% examples, 1019098 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:09,468 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-08-28 05:56:09,470 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-08-28 05:56:09,472 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-08-28 05:56:09,472 : INFO : EPOCH - 4 : training on 10765634 raw words (8387637 effective words) took 8.2s, 1021034 effective words/s\n",
      "2021-08-28 05:56:10,477 : INFO : EPOCH 5 - PROGRESS: at 12.46% examples, 1038522 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:11,482 : INFO : EPOCH 5 - PROGRESS: at 24.97% examples, 1030646 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:12,485 : INFO : EPOCH 5 - PROGRESS: at 37.26% examples, 1029849 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:13,487 : INFO : EPOCH 5 - PROGRESS: at 49.29% examples, 1025840 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:14,491 : INFO : EPOCH 5 - PROGRESS: at 60.67% examples, 1014021 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:15,493 : INFO : EPOCH 5 - PROGRESS: at 72.65% examples, 1013151 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:16,503 : INFO : EPOCH 5 - PROGRESS: at 84.68% examples, 1009638 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:17,504 : INFO : EPOCH 5 - PROGRESS: at 96.49% examples, 1008804 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:17,775 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-08-28 05:56:17,780 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-08-28 05:56:17,786 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-08-28 05:56:17,786 : INFO : EPOCH - 5 : training on 10765634 raw words (8388058 effective words) took 8.3s, 1009066 effective words/s\n",
      "2021-08-28 05:56:18,802 : INFO : EPOCH 6 - PROGRESS: at 12.16% examples, 1005099 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:19,805 : INFO : EPOCH 6 - PROGRESS: at 24.52% examples, 1007566 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:20,809 : INFO : EPOCH 6 - PROGRESS: at 36.28% examples, 998916 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:21,810 : INFO : EPOCH 6 - PROGRESS: at 48.27% examples, 1001578 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:22,815 : INFO : EPOCH 6 - PROGRESS: at 60.32% examples, 1006184 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:23,816 : INFO : EPOCH 6 - PROGRESS: at 72.38% examples, 1007908 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:24,823 : INFO : EPOCH 6 - PROGRESS: at 84.50% examples, 1006792 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:25,823 : INFO : EPOCH 6 - PROGRESS: at 96.58% examples, 1009155 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:26,100 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-08-28 05:56:26,105 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-08-28 05:56:26,110 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-08-28 05:56:26,111 : INFO : EPOCH - 6 : training on 10765634 raw words (8388725 effective words) took 8.3s, 1007954 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-28 05:56:27,114 : INFO : EPOCH 7 - PROGRESS: at 12.26% examples, 1025884 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:28,117 : INFO : EPOCH 7 - PROGRESS: at 24.97% examples, 1032889 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:29,119 : INFO : EPOCH 7 - PROGRESS: at 37.26% examples, 1031372 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:30,123 : INFO : EPOCH 7 - PROGRESS: at 49.66% examples, 1034130 words/s, in_qsize 6, out_qsize 0\n",
      "2021-08-28 05:56:31,132 : INFO : EPOCH 7 - PROGRESS: at 61.94% examples, 1036027 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:32,134 : INFO : EPOCH 7 - PROGRESS: at 74.40% examples, 1037693 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:33,136 : INFO : EPOCH 7 - PROGRESS: at 87.09% examples, 1038571 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:34,148 : INFO : EPOCH 7 - PROGRESS: at 99.50% examples, 1038572 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:34,173 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-08-28 05:56:34,177 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-08-28 05:56:34,182 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-08-28 05:56:34,183 : INFO : EPOCH - 7 : training on 10765634 raw words (8387790 effective words) took 8.1s, 1039397 effective words/s\n",
      "2021-08-28 05:56:35,189 : INFO : EPOCH 8 - PROGRESS: at 12.26% examples, 1020890 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:36,195 : INFO : EPOCH 8 - PROGRESS: at 24.88% examples, 1025514 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:37,199 : INFO : EPOCH 8 - PROGRESS: at 37.26% examples, 1028456 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:38,201 : INFO : EPOCH 8 - PROGRESS: at 49.82% examples, 1036238 words/s, in_qsize 6, out_qsize 0\n",
      "2021-08-28 05:56:39,206 : INFO : EPOCH 8 - PROGRESS: at 61.95% examples, 1035377 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:40,211 : INFO : EPOCH 8 - PROGRESS: at 74.22% examples, 1034134 words/s, in_qsize 6, out_qsize 1\n",
      "2021-08-28 05:56:41,216 : INFO : EPOCH 8 - PROGRESS: at 87.09% examples, 1037248 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:42,223 : INFO : EPOCH 8 - PROGRESS: at 99.50% examples, 1038309 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:42,248 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-08-28 05:56:42,251 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-08-28 05:56:42,258 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-08-28 05:56:42,259 : INFO : EPOCH - 8 : training on 10765634 raw words (8388433 effective words) took 8.1s, 1038916 effective words/s\n",
      "2021-08-28 05:56:43,263 : INFO : EPOCH 9 - PROGRESS: at 12.46% examples, 1039618 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:44,276 : INFO : EPOCH 9 - PROGRESS: at 24.97% examples, 1027001 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:45,282 : INFO : EPOCH 9 - PROGRESS: at 37.06% examples, 1021138 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:46,290 : INFO : EPOCH 9 - PROGRESS: at 49.19% examples, 1019534 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:47,291 : INFO : EPOCH 9 - PROGRESS: at 61.21% examples, 1020355 words/s, in_qsize 6, out_qsize 0\n",
      "2021-08-28 05:56:48,298 : INFO : EPOCH 9 - PROGRESS: at 73.64% examples, 1024695 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:49,299 : INFO : EPOCH 9 - PROGRESS: at 85.93% examples, 1023135 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:50,305 : INFO : EPOCH 9 - PROGRESS: at 98.45% examples, 1026428 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:50,413 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-08-28 05:56:50,422 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-08-28 05:56:50,431 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-08-28 05:56:50,431 : INFO : EPOCH - 9 : training on 10765634 raw words (8387299 effective words) took 8.2s, 1026508 effective words/s\n",
      "2021-08-28 05:56:51,434 : INFO : EPOCH 10 - PROGRESS: at 12.54% examples, 1048107 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:52,438 : INFO : EPOCH 10 - PROGRESS: at 25.26% examples, 1044113 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:53,450 : INFO : EPOCH 10 - PROGRESS: at 37.77% examples, 1043112 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:54,457 : INFO : EPOCH 10 - PROGRESS: at 49.91% examples, 1036391 words/s, in_qsize 6, out_qsize 0\n",
      "2021-08-28 05:56:55,459 : INFO : EPOCH 10 - PROGRESS: at 62.03% examples, 1036161 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:56,462 : INFO : EPOCH 10 - PROGRESS: at 74.03% examples, 1031462 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:57,467 : INFO : EPOCH 10 - PROGRESS: at 86.62% examples, 1031744 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:58,469 : INFO : EPOCH 10 - PROGRESS: at 99.06% examples, 1034195 words/s, in_qsize 5, out_qsize 0\n",
      "2021-08-28 05:56:58,536 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-08-28 05:56:58,536 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-08-28 05:56:58,540 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-08-28 05:56:58,541 : INFO : EPOCH - 10 : training on 10765634 raw words (8389358 effective words) took 8.1s, 1034668 effective words/s\n",
      "2021-08-28 05:56:58,542 : INFO : Doc2Vec lifecycle event {'msg': 'training on 107656340 raw words (83882141 effective words) took 82.2s, 1020579 effective words/s', 'datetime': '2021-08-28T05:56:58.542571', 'gensim': '4.0.1', 'python': '3.8.9 (tags/v3.8.9:a743f81, Apr  2 2021, 11:10:41) [MSC v.1928 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n"
     ]
    }
   ],
   "source": [
    "#Model Training\n",
    "model.train(docs, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd1c7dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3508/3508 [00:23<00:00, 148.90it/s]\n"
     ]
    }
   ],
   "source": [
    "#Read the test JSON and rank stuff\n",
    "to_tag = readjson('data/test_q.json')\n",
    "docs = np.array(docs)\n",
    "titles = np.array(titles)\n",
    "results = to_tag\n",
    "\n",
    "for i in tqdm(range(len(to_tag))):\n",
    "    to_check = to_tag[i]['title_id']\n",
    "    to_check = titlesearch(to_check)\n",
    "    \n",
    "    title_vector = model.infer_vector(to_check[0])\n",
    "    ranking = cosinerank(title_vector,to_tag[i]['candidates'])\n",
    "    \n",
    "    temp = []\n",
    "    for j in range(len(ranking)):\n",
    "        temp.append(ranking[j][1])\n",
    "        \n",
    "    results[i]['candidates'] = temp\n",
    "    \n",
    "    #ranking = model.dv.most_similar([title_vector],topn=len(model.dv))\n",
    "    #results[i]['candidates'] = docmatch(ranking,to_tag[i]['candidates'])\n",
    "      \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8ad7606e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#Read the test JSON and rank stuff\\nto_tag = readjson('data/test_q.json')\\ndocs = np.array(docs)\\ntitles = np.array(titles)\\nresults = to_tag\\n\\nfor i in tqdm(range(len(to_tag))):\\n    taglist = to_tag[i]['candidates']\\n    \\n    doc_tokens = []\\n    for key in taglist:\\n        val = np.where(docs==key)\\n        doc_tokens.append(docs[(val[0][0])])\\n        \\n    val = np.where(titles==to_tag[i]['title_id'])\\n    title_token = titles[(val[0][0])][0]\\n    \\n    sorted_docs = cosinerank(title_token,doc_tokens)\\n    \\n    sorted_docs_column = []\\n    for j in range(len(sorted_docs)):\\n        sorted_docs_column.append(sorted_docs[j][1])\\n    results[i]['candidates'] = sorted_docs_column\\n\""
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Read the test JSON and rank stuff\n",
    "to_tag = readjson('data/test_q.json')\n",
    "docs = np.array(docs)\n",
    "titles = np.array(titles)\n",
    "results = to_tag\n",
    "\n",
    "for i in tqdm(range(len(to_tag))):\n",
    "    taglist = to_tag[i]['candidates']\n",
    "    \n",
    "    doc_tokens = []\n",
    "    for key in taglist:\n",
    "        val = np.where(docs==key)\n",
    "        doc_tokens.append(docs[(val[0][0])])\n",
    "        \n",
    "    val = np.where(titles==to_tag[i]['title_id'])\n",
    "    title_token = titles[(val[0][0])][0]\n",
    "    \n",
    "    sorted_docs = cosinerank(title_token,doc_tokens)\n",
    "    \n",
    "    sorted_docs_column = []\n",
    "    for j in range(len(sorted_docs)):\n",
    "        sorted_docs_column.append(sorted_docs[j][1])\n",
    "    results[i]['candidates'] = sorted_docs_column\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b18ea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "writejson(results,'data/suggestion.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "165281df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.20003039e-01 -5.67086041e-02 -3.41204330e-02  8.65936056e-02\n",
      " -1.69310346e-01  6.33304358e-01  1.55121922e-01  1.51920462e+00\n",
      " -2.07499325e-01 -4.98444378e-01  3.87282133e-01 -1.14784867e-01\n",
      " -2.58946389e-01  1.42954409e+00 -4.82909739e-01  6.45391792e-02\n",
      " -2.71909852e-02  5.84906816e-01  1.56846782e-03  6.94743395e-01\n",
      " -1.26823202e-01  1.75164521e-01  9.90388632e-01 -1.66007541e-02\n",
      "  5.14289021e-01  1.08363010e-01  3.61230299e-02  1.12642936e-01\n",
      "  7.50880480e-01 -6.28488064e-01 -5.25296748e-01  2.00667453e+00\n",
      " -2.70202667e-01  1.73684388e-01  1.68475711e+00 -6.98680580e-01\n",
      "  5.26426435e-01  3.13155539e-02 -1.04095154e-01 -3.08611274e-01\n",
      "  1.07599473e+00 -7.66604483e-01  1.09134614e+00 -8.74592960e-01\n",
      " -5.16031325e-01 -5.51534474e-01 -2.67924756e-01 -8.79276991e-01\n",
      " -8.37159514e-01  6.91151440e-01 -1.02591538e+00  7.73221493e-01\n",
      "  5.19679725e-01 -1.07962632e+00 -4.26729053e-01 -4.66520160e-01\n",
      "  2.93620855e-01 -1.11001976e-01 -2.31866643e-01 -2.75087655e-01\n",
      " -1.61305532e-01  4.48993444e-01  2.74247676e-01 -1.60891339e-01\n",
      "  3.76327217e-01  2.13072021e-02 -3.76635373e-01  5.33081114e-01\n",
      "  4.68964577e-01  6.45477772e-02  7.09430814e-01  2.78917551e-01\n",
      "  5.01486599e-01  3.39367807e-01 -2.30066455e-03 -5.66022813e-01\n",
      "  1.04807353e+00 -1.18198153e-02 -1.84944257e-01  2.78766066e-01\n",
      "  4.22960460e-01 -6.81102574e-01 -6.98423013e-02  1.40559363e+00\n",
      " -1.03352427e+00  2.66258448e-01  1.52827132e+00  7.49711767e-02\n",
      " -2.27193478e-02 -1.06817710e+00 -3.30424488e-01  4.90275592e-01\n",
      " -8.45685601e-01  5.43496072e-01  5.14968157e-01  1.03588367e+00\n",
      "  6.66160285e-01 -2.35802665e-01 -7.77267516e-01  9.13502455e-01\n",
      " -3.14981133e-01  2.78526872e-01  6.58427551e-03 -3.66342306e-01\n",
      " -1.43869191e-01 -4.02954191e-01  1.41009301e-01  3.30188483e-01\n",
      " -2.15542674e+00 -9.60552692e-02  1.32599995e-01  1.21091820e-01\n",
      "  1.24243116e+00  2.84428865e-01 -8.22051018e-02  9.87963915e-01\n",
      " -2.74580777e-01  7.22353578e-01  1.48060411e-01 -6.40290558e-01\n",
      "  4.35344100e-01 -1.62810996e-01  1.09235978e+00  3.15478593e-01\n",
      " -5.19435048e-01  1.08357739e+00 -1.36105251e+00 -3.95361781e-01\n",
      " -4.63491410e-01 -4.98287320e-01 -7.52375871e-02  9.91946995e-01\n",
      "  7.24719107e-01 -6.77534163e-01 -2.11587146e-01 -4.82859313e-01\n",
      " -2.85577446e-01 -6.47749424e-01  9.12643969e-01  1.04612195e+00\n",
      " -7.25390673e-01 -1.61017045e-01  2.47907057e-01  2.78223008e-01\n",
      " -1.00223601e-01 -1.39886409e-01  6.87233686e-01 -3.31920773e-01\n",
      "  8.68263721e-01  7.91703910e-02]\n"
     ]
    }
   ],
   "source": [
    "print(model.dv['doc49117'])\n",
    "#title_vector = model.infer_vector(['Anne','Walmsley'])\n",
    "#print(model.dv.most_similar([title_vector],topn=len(model.dv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d52763",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
